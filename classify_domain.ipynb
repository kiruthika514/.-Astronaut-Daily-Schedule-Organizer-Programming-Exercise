{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_domain.ipynb",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.3.1\n"
      ],
      "metadata": {
        "id": "1WgLKIKHFXfn",
        "outputId": "15da3dd4-6c94-466f-fce2-977f2ec8b22e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras==2.3.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.11/dist-packages (from keras==2.3.1) (1.14.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras==2.3.1) (1.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from keras==2.3.1) (6.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras==2.3.1) (3.12.1)\n",
            "Collecting keras-applications>=1.0.6 (from keras==2.3.1)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting keras-preprocessing>=1.0.5 (from keras==2.3.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.8/377.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikeras 0.13.0 requires keras>=3.2.0, but you have keras 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires keras>=3.5.0, but you have keras 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras tensorflow -y\n"
      ],
      "metadata": {
        "id": "dIx5DI1_I_jF",
        "outputId": "559fbfea-9cde-4794-b24a-0b8b7aeda7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Keras 2.3.1\n",
            "Uninstalling Keras-2.3.1:\n",
            "  Successfully uninstalled Keras-2.3.1\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --upgrade\n"
      ],
      "metadata": {
        "id": "PDqZh9d6JUd_",
        "outputId": "352e4bfc-6567-4ce6-be6e-e1c875f38fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow)\n",
            "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m862.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.9.0 ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W5xD8ZAJibMD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)  # This should print a valid version like 2.x.x\n"
      ],
      "metadata": {
        "id": "lzkZV32aij3I",
        "outputId": "b0e2554d-91a6-4ec0-d02b-958b5ee137b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras[tensorflow]\n"
      ],
      "metadata": {
        "id": "YEpsfkzgjOVi",
        "outputId": "8064b3e5-070a-4046-9ae8-196c10dddd7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (1.6.1)\n",
            "Requirement already satisfied: tensorflow>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from scikeras[tensorflow]) (2.19.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (3.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.70.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras[tensorflow]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xxTKbivVCelA"
      },
      "cell_type": "code",
      "source": [
        "from pickle import load, dump\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import random\n",
        "from numpy import array"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_flg_9GjGo1-",
        "outputId": "68372809-f529-4488-966b-7db2c789592c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/finalattention\"  # Change 'your_project_folder' to any name you want\n",
        "\n",
        "# Define required folders\n",
        "folders = [\n",
        "    \"Description\",\n",
        "    \"Features\",\n",
        "    \"model/results\"\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)\n",
        "\n",
        "print(f\"Folders created under: {base_dir}\")\n"
      ],
      "metadata": {
        "id": "RSjJzl7_kdcX",
        "outputId": "6574d25b-a971-4edc-edba-aa7eb65c830e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created under: /content/drive/MyDrive/finalattention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/remote_sensing_image_captioning/Dataset \"https://github.com/chan64/remote_sensing_image_captioning/tree/master/Dataset\"\n"
      ],
      "metadata": {
        "id": "Wb-9sciI00Nk",
        "outputId": "1140f498-a40b-434f-9ad0-047bcea078fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-12 14:51:44--  https://github.com/chan64/remote_sensing_image_captioning/tree/master/Dataset\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/content/remote_sensing_image_captioning/Dataset/Dataset’\n",
            "\n",
            "Dataset                 [  <=>               ] 220.02K   903KB/s    in 0.2s    \n",
            "\n",
            "2025-03-12 14:51:45 (903 KB/s) - ‘/content/remote_sensing_image_captioning/Dataset/Dataset’ saved [225300]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/remote_sensing_image_captioning/Dataset\", \"/content/drive/MyDrive/finalattention/Dataset\")\n"
      ],
      "metadata": {
        "id": "7ZUlein4132T",
        "outputId": "16124a4e-2fdb-4dfc-8335-4bc9e3f964c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/finalattention/Dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/finalattention/Dataset\"\n"
      ],
      "metadata": {
        "id": "x3R3su9R2NH4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FymXq03CelD"
      },
      "cell_type": "code",
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, 'r')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "    doc = load_doc(filename)\n",
        "    dataset = list()\n",
        "    # process line by line\n",
        "    for line in doc.split('\\n'):\n",
        "        # skip empty lines\n",
        "        if len(line) < 1:\n",
        "            continue\n",
        "        # get the image identifier\n",
        "        identifier = line.split(' ')[0]\n",
        "        dataset.append(identifier)\n",
        "    return set(dataset)\n",
        "\n",
        "# load photo features\n",
        "def load_video_features(filename, dataset):\n",
        "    # load all features\n",
        "    all_features = load(open(filename, 'rb'))\n",
        "    # filter features\n",
        "    features = {k: all_features[k][:256] for k in dataset}\n",
        "    return features"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGkpK7ctCelF",
        "outputId": "71616ea4-142c-4e82-b22f-79a5eb9d680a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "#load training dataset (6K)\n",
        "filename = '/content/drive/MyDrive/finalattention/Description/trainuc.txt'\n",
        "train = load_set(filename)\n",
        "print('Train: %d' % len(train))\n",
        "#load training dataset (6K)\n",
        "filename = '/content/drive/MyDrive/finalattention/Description/testuc.txt'\n",
        "test = load_set(filename)\n",
        "print('Test: %d' % len(test))\n",
        "'''\n",
        "#load c2d features\n",
        "train_vid_features = load_video_features('dataset_one_hot_train.pkl', train)\n",
        "print('C2D: train=%d' % len(train_vid_features))\n",
        "\n",
        "#load c2d features\n",
        "test_vid_features = load_video_features('dataset_one_hot_test.pkl', test)\n",
        "print('C2D: train=%d' % len(test_vid_features))\n",
        "class_label=load(open('/home/mh/mywork/dataset/MSVD/features/class_features/msvd_video_class_label_6.pkl','rb'))\n",
        "\n",
        "#load c2d features\n",
        "train_vid_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/msvd_sem_scn_300.pkl', train)\n",
        "print('C2D: train=%d' % len(train_vid_features))\n",
        "\n",
        "#load c2d features\n",
        "test_vid_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/msvd_sem_scn_300.pkl', test)\n",
        "print('C2D: train=%d' % len(test_vid_features))\n",
        "\n",
        "'''\n",
        "#load c2d features\n",
        "train_vid_features = load_video_features('/content/drive/MyDrive/finalattention/Features/features_uc_resnet152_updated.pkl', train)\n",
        "\n",
        "print('Loaded: train=%d' % len(train_vid_features))\n",
        "\n",
        "#load c2d features\n",
        "test_vid_features = load_video_features('/content/drive/MyDrive/finalattention/Features/features_uc_resnet152_updated.pkl', test)\n",
        "print('Loaded: test=%d' % len(test_vid_features))\n",
        "class_label=load(open('/content/drive/MyDrive/finalattention/Features/dataset_one_hot_uc.pkl','rb'))\n",
        "\n",
        "\n",
        "#print(train_vid_features['05_010'])\n",
        "\n",
        "Xtrain=list()\n",
        "Ytrain=list()\n",
        "for i in train_vid_features:\n",
        "    Xtrain.append(train_vid_features[i][0])\n",
        "    #print(i)\n",
        "    #x = i.split('_')[0]\n",
        "    Ytrain.append(class_label[i])\n",
        "\n",
        "print(Xtrain[0])\n",
        "Xtrain=np.array(Xtrain)\n",
        "print(Xtrain.shape)\n",
        "\n",
        "print(Ytrain[0])\n",
        "Ytrain=np.array(Ytrain)\n",
        "print(Ytrain.shape)\n",
        "\n",
        "Xtest = list()\n",
        "Ytest = list()\n",
        "for i in test_vid_features:\n",
        "    Xtest.append(test_vid_features[i][0])\n",
        "    Ytest.append(class_label[i])\n",
        "\n",
        "Xtest=np.array(Xtest)\n",
        "print(Xtest.shape)\n",
        "\n",
        "Ytest=np.array(Ytest)\n",
        "print(Ytest.shape)\n",
        "\n",
        "\n",
        "'''\n",
        "Xtest=list()\n",
        "Ytest=list()\n",
        "for i in test_vid_features:\n",
        "    Xtest.append(test_vid_features[i][0])\n",
        "    Ytest.append(class_label[i])\n",
        "\n",
        "Xtest=np.array(Xtest)\n",
        "print(Xtest.shape)\n",
        "Ytest=np.array(Ytest)\n",
        "print(Ytest.shape)\n",
        "\n",
        "#load c2d features\n",
        "train_c2d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_resnet152_vlad_features_k_100.pkl', train)\n",
        "print('C2D: train=%d' % len(train_c2d_features))\n",
        "\n",
        "#load c3d features\n",
        "train_c3d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_c3d_vlad_features_k_100.pkl', train)\n",
        "print('C3D: train=%d' % len(train_c3d_features))\n",
        "\n",
        "#load semantic features\n",
        "train_semantic_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/msvd_sem_scn_300.pkl', train)\n",
        "print('Semantic: train=%d' % len(train_semantic_features))\n",
        "\n",
        "Xtrain=list()\n",
        "Ytrain=list()\n",
        "for i in train_c2d_features:\n",
        "    c2d=np.array(train_c2d_features[i])\n",
        "    c3d=np.array(train_c3d_features[i])\n",
        "    sem=np.array(train_semantic_features[i])\n",
        "    Xtrain.append(np.concatenate((c2d,c3d,sem),axis=0))\n",
        "    Ytrain.append(Ytrain_label[i])\n",
        "\n",
        "Xtrain=np.array(Xtrain)\n",
        "print(Xtrain.shape)\n",
        "Ytrain=np.array(Ytrain)\n",
        "print(Ytrain.shape)\n",
        "\n",
        "Xtest=list()\n",
        "Ytest=list()\n",
        "for i in test_c2d_features:\n",
        "    c2d=np.array(test_c2d_features[i])\n",
        "    c3d=np.array(test_c3d_features[i])\n",
        "    sem=np.array(test_semantic_features[i])\n",
        "    Xtest.append(np.concatenate((c2d,c3d,sem),axis=0))\n",
        "    Ytest.append(Ytest_label[i])\n",
        "\n",
        "Xtest=np.array(Xtest)\n",
        "print(Xtest.shape)\n",
        "Ytest=np.array(Ytest)\n",
        "print(Ytest.shape)\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1260\n",
            "Test: 420\n",
            "Loaded: train=1260\n",
            "Loaded: test=420\n",
            "[0.09365865 0.05717707 4.2325883  ... 1.8605973  0.22527066 0.        ]\n",
            "(1260, 2048)\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(1260, 21)\n",
            "(420, 2048)\n",
            "(420, 21)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nXtest=list()\\nYtest=list()\\nfor i in test_vid_features:\\n    Xtest.append(test_vid_features[i][0])\\n    Ytest.append(class_label[i])\\n\\nXtest=np.array(Xtest)\\nprint(Xtest.shape)\\nYtest=np.array(Ytest)\\nprint(Ytest.shape)\\n\\n#load c2d features\\ntrain_c2d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_resnet152_vlad_features_k_100.pkl', train)\\nprint('C2D: train=%d' % len(train_c2d_features))\\n\\n#load c3d features\\ntrain_c3d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_c3d_vlad_features_k_100.pkl', train)\\nprint('C3D: train=%d' % len(train_c3d_features))\\n\\n#load semantic features\\ntrain_semantic_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/msvd_sem_scn_300.pkl', train)\\nprint('Semantic: train=%d' % len(train_semantic_features))\\n\\nXtrain=list()\\nYtrain=list()\\nfor i in train_c2d_features:\\n    c2d=np.array(train_c2d_features[i])\\n    c3d=np.array(train_c3d_features[i])\\n    sem=np.array(train_semantic_features[i])\\n    Xtrain.append(np.concatenate((c2d,c3d,sem),axis=0))\\n    Ytrain.append(Ytrain_label[i])\\n\\nXtrain=np.array(Xtrain)\\nprint(Xtrain.shape)\\nYtrain=np.array(Ytrain)\\nprint(Ytrain.shape)\\n\\nXtest=list()\\nYtest=list()\\nfor i in test_c2d_features:\\n    c2d=np.array(test_c2d_features[i])\\n    c3d=np.array(test_c3d_features[i])\\n    sem=np.array(test_semantic_features[i])\\n    Xtest.append(np.concatenate((c2d,c3d,sem),axis=0))\\n    Ytest.append(Ytest_label[i])\\n\\nXtest=np.array(Xtest)\\nprint(Xtest.shape)\\nYtest=np.array(Ytest)\\nprint(Ytest.shape)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "BeJYnFoPCelJ",
        "outputId": "4d2d64aa-9561-4879-c2ed-ae4adbd1358e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "features1 = load(open('/content/drive/MyDrive/finalattention/Features/dataset_one_hot_newids.pkl','rb'))\n",
        "print((features1.keys()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['100_050', '106_105', '103_068', '111_144', '107_028', '109_002', '104_042', '106_138', '106_118', '104_002', '106_059', '100_082', '108_073', '112_088', '100_051', '109_127', '111_054', '112_071', '112_097', '107_013', '102_044', '104_024', '103_019', '110_039', '106_110', '100_038', '100_124', '108_131', '112_010', '100_071', '109_150', '110_051', '104_084', '107_026', '110_052', '106_104', '101_013', '108_096', '108_150', '106_143', '103_059', '109_078', '103_018', '100_006', '100_091', '105_027', '106_120', '103_039', '106_094', '108_032', '105_007', '102_066', '103_143', '108_137', '109_114', '108_021', '100_149', '110_042', '111_011', '103_074', '102_069', '103_058', '100_005', '108_109', '104_082', '104_073', '103_114', '106_003', '109_147', '104_029', '108_055', '109_124', '111_121', '104_069', '108_124', '100_137', '103_139', '100_069', '111_058', '108_136', '109_108', '106_139', '103_144', '100_022', '112_014', '105_018', '112_056', '102_028', '103_078', '101_027', '109_084', '109_011', '106_014', '104_059', '111_088', '106_119', '100_018', '108_058', '109_136', '109_104', '102_043', '100_086', '113_017', '106_113', '113_007', '104_085', '100_099', '106_062', '106_053', '100_043', '103_063', '100_034', '102_071', '112_030', '111_079', '113_018', '109_066', '103_146', '106_095', '109_126', '106_036', '106_145', '109_096', '109_040', '108_067', '109_115', '109_019', '107_029', '104_051', '106_066', '113_019', '109_089', '103_008', '107_004', '108_143', '109_133', '103_029', '104_056', '102_020', '111_128', '106_052', '102_024', '102_035', '100_084', '113_001', '109_092', '103_062', '103_104', '103_051', '106_132', '105_039', '104_031', '112_050', '106_086', '111_056', '102_001', '100_092', '106_044', '102_056', '109_080', '110_056', '100_059', '111_105', '111_023', '106_037', '111_126', '106_011', '107_006', '106_081', '103_113', '109_075', '112_080', '110_024', '103_124', '102_014', '103_033', '113_024', '111_014', '111_050', '107_046', '108_033', '112_079', '103_128', '106_006', '103_041', '100_077', '112_052', '105_020', '109_088', '111_095', '111_122', '106_115', '109_013', '100_060', '108_012', '111_029', '104_052', '103_013', '102_045', '105_043', '106_116', '108_044', '100_057', '106_109', '110_010', '100_025', '111_047', '101_021', '109_062', '108_004', '105_008', '106_024', '108_139', '111_049', '109_139', '100_011', '100_135', '105_024', '110_035', '104_040', '103_150', '108_011', '100_105', '101_002', '109_050', '100_062', '107_023', '108_102', '100_044', '106_114', '108_104', '100_031', '104_005', '103_127', '102_064', '111_053', '104_035', '108_126', '100_111', '100_129', '106_030', '109_025', '109_101', '108_081', '110_013', '111_071', '106_026', '112_059', '106_002', '108_062', '100_020', '111_089', '108_017', '110_030', '103_090', '103_010', '108_134', '103_071', '105_050', '104_095', '104_013', '110_027', '105_040', '103_096', '107_019', '107_011', '109_083', '105_015', '112_099', '102_065', '111_123', '107_030', '100_065', '103_089', '104_081', '108_037', '106_013', '100_049', '108_122', '112_068', '107_016', '108_025', '104_072', '108_065', '103_006', '111_100', '108_066', '105_046', '101_003', '108_007', '108_117', '103_109', '103_060', '100_110', '109_009', '111_037', '109_023', '109_067', '111_084', '112_067', '106_005', '112_072', '104_043', '100_047', '109_117', '107_018', '103_030', '109_123', '110_008', '103_131', '106_075', '106_076', '103_035', '101_014', '112_031', '103_075', '111_073', '104_092', '109_131', '104_087', '108_121', '112_092', '101_024', '109_052', '109_018', '106_009', '109_020', '103_061', '109_142', '106_019', '108_080', '109_035', '104_075', '103_105', '108_022', '112_053', '108_119', '104_050', '112_076', '106_083', '102_002', '103_046', '100_037', '108_024', '112_041', '106_135', '112_013', '110_050', '104_071', '113_012', '108_014', '112_008', '108_047', '110_011', '100_132', '109_105', '106_045', '108_042', '111_057', '112_016', '106_048', '103_016', '101_009', '100_066', '104_063', '109_058', '109_102', '111_015', '109_065', '106_126', '109_082', '111_034', '104_011', '109_081', '105_037', '106_015', '109_148', '113_025', '106_031', '102_072', '107_045', '112_022', '110_021', '109_076', '108_076', '108_144', '108_035', '100_008', '103_086', '112_084', '108_148', '113_020', '105_010', '113_023', '109_034', '112_075', '104_097', '109_140', '109_141', '104_061', '113_016', '111_072', '111_009', '108_097', '103_023', '106_068', '100_102', '111_033', '100_017', '109_021', '109_041', '109_059', '109_061', '112_082', '102_038', '108_043', '103_082', '111_101', '108_083', '109_087', '111_010', '100_126', '100_026', '107_039', '102_039', '111_146', '110_045', '100_048', '104_038', '108_052', '100_096', '108_082', '103_093', '111_148', '107_034', '111_110', '109_042', '100_046', '100_064', '112_005', '111_067', '108_023', '100_127', '110_005', '103_098', '108_050', '106_041', '111_134', '111_131', '100_113', '111_086', '106_084', '111_066', '103_001', '104_041', '106_146', '100_139', '111_059', '111_097', '109_001', '103_132', '100_001', '105_009', '106_010', '111_052', '110_023', '102_032', '109_027', '103_070', '104_036', '113_013', '106_067', '111_068', '108_105', '111_022', '109_125', '112_060', '106_089', '111_061', '106_069', '100_067', '109_106', '108_078', '104_046', '106_117', '113_003', '108_061', '103_022', '104_026', '111_075', '106_136', '105_006', '104_030', '113_004', '111_036', '102_034', '104_074', '109_146', '108_001', '111_083', '106_124', '108_087', '109_120', '106_100', '100_123', '103_047', '103_088', '108_133', '100_136', '112_095', '112_089', '100_045', '109_107', '105_019', '103_099', '111_046', '105_025', '100_088', '113_015', '104_033', '112_042', '112_001', '108_086', '104_022', '112_033', '100_079', '107_008', '111_092', '103_003', '107_017', '100_023', '103_112', '106_137', '111_013', '108_029', '106_057', '103_137', '103_025', '100_114', '105_044', '112_077', '108_118', '106_065', '100_029', '110_055', '107_037', '112_040', '104_025', '111_099', '103_097', '106_023', '103_117', '109_111', '108_010', '109_043', '104_023', '111_043', '111_070', '113_022', '109_073', '112_058', '109_056', '101_012', '102_031', '102_026', '111_135', '105_047', '100_094', '102_051', '102_021', '113_021', '109_022', '110_037', '103_028', '100_003', '105_016', '100_098', '106_080', '111_145', '108_041', '111_080', '108_088', '103_121', '108_057', '108_048', '106_042', '111_039', '111_113', '108_111', '110_029', '108_056', '101_004', '111_115', '100_095', '107_021', '111_055', '109_060', '106_046', '108_112', '100_012', '104_021', '108_114', '111_137', '103_077', '105_049', '102_041', '112_018', '100_063', '111_041', '108_008', '108_070', '100_089', '113_014', '102_009', '108_053', '109_031', '100_107', '108_071', '109_039', '102_018', '108_140', '110_031', '108_108', '103_119', '111_031', '103_021', '111_069', '100_120', '106_070', '106_092', '109_014', '103_012', '109_097', '103_125', '106_016', '103_129', '103_031', '107_014', '108_054', '107_031', '103_103', '105_014', '111_102', '100_145', '112_100', '104_096', '100_035', '104_066', '101_010', '103_142', '103_091', '100_109', '103_064', '100_118', '108_142', '106_043', '107_027', '103_136', '111_106', '103_017', '112_073', '100_101', '100_078', '105_017', '108_015', '103_054', '102_015', '109_093', '108_146', '100_009', '106_149', '103_009', '111_025', '103_007', '112_047', '103_147', '103_080', '100_021', '106_148', '107_044', '109_005', '111_081', '108_077', '103_050', '104_080', '110_038', '109_135', '110_041', '111_136', '111_114', '100_052', '108_101', '105_011', '100_134', '106_108', '112_061', '112_012', '104_009', '103_123', '104_089', '112_096', '109_086', '100_146', '100_083', '110_033', '104_017', '106_055', '111_087', '106_004', '107_047', '107_012', '106_058', '100_133', '105_002', '107_040', '111_103', '104_057', '112_011', '107_024', '103_149', '110_012', '106_125', '100_142', '106_054', '100_143', '103_108', '109_048', '106_103', '104_048', '111_065', '104_003', '103_042', '106_122', '100_039', '113_009', '108_147', '109_038', '112_062', '100_007', '109_077', '104_007', '111_064', '112_026', '112_048', '100_117', '107_010', '102_030', '100_004', '106_061', '111_063', '108_063', '108_132', '104_070', '102_008', '101_016', '106_107', '106_147', '106_101', '103_066', '111_129', '105_026', '106_102', '109_004', '108_079', '110_018', '109_017', '103_107', '106_050', '111_004', '102_025', '102_006', '100_125', '105_041', '104_044', '106_129', '101_011', '106_034', '108_034', '108_084', '103_045', '110_060', '108_072', '105_035', '110_054', '112_021', '106_072', '107_035', '101_031', '105_023', '111_026', '102_049', '107_043', '100_076', '103_083', '112_020', '109_098', '104_039', '113_005', '103_015', '102_060', '111_109', '110_003', '108_092', '109_006', '103_011', '102_046', '109_137', '103_014', '103_135', '112_081', '112_025', '106_001', '111_141', '105_022', '110_025', '103_076', '103_081', '111_093', '111_018', '110_057', '102_011', '112_035', '101_019', '109_036', '106_033', '100_072', '110_007', '111_032', '109_045', '104_004', '103_044', '108_064', '102_059', '108_116', '111_108', '109_070', '111_002', '100_002', '111_082', '108_046', '100_147', '104_094', '109_118', '105_032', '103_036', '104_058', '104_060', '106_021', '112_086', '107_009', '106_047', '104_010', '107_001', '109_112', '106_049', '106_035', '112_063', '102_017', '100_080', '103_111', '103_092', '101_005', '109_053', '111_030', '113_002', '103_101', '106_071', '104_093', '109_026', '111_024', '108_020', '103_141', '112_038', '105_034', '100_106', '100_068', '109_003', '100_055', '111_090', '112_070', '109_063', '102_040', '111_096', '106_121', '103_102', '107_005', '103_115', '106_012', '109_069', '104_062', '107_048', '111_119', '109_046', '109_074', '111_019', '103_056', '102_047', '102_070', '104_016', '100_016', '104_055', '104_014', '102_033', '109_130', '103_002', '113_010', '112_087', '108_123', '112_032', '103_024', '105_013', '107_025', '110_048', '100_087', '111_001', '111_149', '102_012', '109_094', '108_115', '105_042', '108_016', '110_044', '101_015', '106_032', '103_148', '108_040', '111_007', '103_032', '103_027', '108_095', '110_022', '103_048', '109_049', '106_078', '100_085', '106_141', '100_054', '102_003', '111_077', '106_040', '108_031', '104_034', '106_038', '105_038', '103_040', '100_070', '103_026', '105_045', '101_001', '102_022', '102_057', '108_038', '107_033', '105_030', '108_103', '102_007', '102_019', '101_020', '104_090', '101_007', '106_073', '111_021', '103_120', '113_006', '106_130', '113_008', '107_050', '100_108', '102_068', '106_029', '105_012', '102_023', '108_099', '100_042', '111_028', '105_036', '100_024', '105_048', '106_134', '107_038', '111_076', '111_104', '109_024', '103_049', '112_027', '103_130', '112_064', '109_028', '112_002', '106_088', '103_116', '106_131', '108_005', '103_005', '108_085', '103_072', '112_069', '106_077', '112_054', '108_019', '103_079', '103_100', '111_140', '100_138', '103_067', '111_078', '106_091', '101_032', '108_068', '111_008', '104_065', '104_037', '106_022', '108_106', '104_012', '108_028', '108_060', '112_066', '103_004', '109_079', '106_020', '108_069', '103_084', '111_133', '100_115', '100_014', '105_005', '103_087', '104_054', '106_025', '105_021', '103_134', '112_037', '100_074', '106_039', '108_135', '102_036', '101_017', '111_020', '109_012', '104_047', '110_002', '102_013', '100_058', '109_099', '101_028', '104_020', '111_138', '108_049', '104_018', '100_073', '111_051', '102_061', '104_006', '104_067', '111_060', '100_090', '103_133', '111_074', '102_053', '100_100', '103_126', '104_001', '108_075', '107_022', '100_112', '112_094', '100_015', '101_029', '108_141', '104_077', '110_032', '102_048', '109_007', '108_089', '112_029', '108_002', '109_015', '111_027', '112_024', '105_033', '102_062', '106_123', '100_036', '104_045', '111_048', '109_057', '110_004', '105_052', '106_051', '108_074', '111_017', '108_003', '109_144', '100_010', '112_091', '111_143', '112_009', '108_127', '111_120', '107_041', '108_149', '106_056', '111_098', '108_090', '100_128', '100_148', '102_055', '109_016', '111_130', '111_124', '112_006', '110_014', '106_063', '111_006', '106_093', '101_022', '111_116', '104_053', '111_085', '108_145', '108_009', '112_057', '106_097', '100_032', '111_005', '110_006', '104_049', '103_053', '100_013', '106_111', '101_008', '100_040', '104_083', '106_098', '109_010', '102_042', '111_118', '109_008', '108_093', '105_051', '110_026', '109_145', '103_057', '100_056', '109_037', '100_027', '108_094', '110_040', '105_004', '108_039', '111_111', '106_140', '110_059', '108_006', '100_131', '106_087', '110_009', '109_103', '112_039', '111_042', '111_091', '103_095', '100_103', '100_019', '112_034', '111_040', '101_018', '110_017', '108_125', '112_003', '111_035', '106_144', '104_086', '103_110', '107_007', '112_036', '109_047', '106_099', '109_032', '107_015', '103_069', '104_028', '112_004', '104_064', '106_150', '110_049', '112_049', '109_109', '109_128', '109_138', '103_065', '104_027', '108_098', '111_125', '106_018', '110_036', '103_043', '108_120', '110_019', '104_015', '109_129', '109_100', '110_043', '104_008', '111_132', '108_100', '108_051', '109_143', '108_129', '100_104', '109_116', '103_020', '103_145', '100_093', '109_030', '100_075', '109_055', '102_016', '103_094', '100_144', '101_026', '107_032', '100_150', '111_127', '100_116', '108_138', '107_020', '104_019', '111_112', '103_118', '100_119', '102_058', '109_134', '102_004', '109_122', '103_085', '104_078', '106_090', '107_003', '111_038', '104_088', '110_028', '100_061', '108_059', '108_128', '108_036', '109_090', '100_033', '109_085', '107_002', '103_073', '112_065', '112_017', '103_106', '110_016', '105_028', '106_060', '103_140', '111_012', '105_031', '113_026', '106_106', '102_050', '108_026', '103_138', '102_010', '100_141', '106_007', '108_018', '106_082', '106_074', '111_107', '113_011', '109_029', '104_032', '106_008', '112_023', '111_117', '106_079', '100_028', '100_041', '105_001', '112_044', '107_036', '108_130', '100_030', '109_113', '103_055', '106_017', '106_096', '109_095', '105_003', '109_033', '110_046', '102_054', '109_132', '109_044', '110_053', '111_016', '102_029', '112_055', '109_110', '102_052', '103_038', '112_051', '111_062', '103_034', '108_110', '111_094', '111_147', '112_028', '112_015', '100_130', '107_042', '100_081', '109_051', '112_098', '112_074', '104_079', '112_045', '109_068', '102_037', '100_053', '102_005', '111_142', '112_019', '100_140', '101_006', '101_023', '112_090', '100_122', '112_078', '106_133', '107_049', '111_044', '103_052', '106_127', '110_020', '109_064', '102_063', '109_091', '101_025', '109_149', '111_150', '103_122', '102_073', '110_034', '106_085', '105_029', '108_113', '106_112', '112_007', '106_142', '109_054', '109_071', '112_043', '110_015', '110_001', '108_107', '112_083', '112_085', '108_091', '106_064', '108_030', '104_068', '109_119', '111_139', '104_091', '102_067', '103_037', '109_121', '104_076', '110_058', '102_027', '110_047', '112_046', '112_093', '100_097', '108_013', '106_128', '108_045', '106_027', '111_003', '111_045', '101_030', '109_072', '100_121', '106_028', '108_027'])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dUX8ap0kCelM",
        "outputId": "8d99160c-b4bc-481d-f83c-57deccc73112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(X,Y,batch_size):\n",
        "    # loop for ever over images\n",
        "    batch_features = np.zeros((batch_size, 830))\n",
        "    batch_labels = np.zeros((batch_size,14))\n",
        "    while 1:\n",
        "        for i in range(batch_size):\n",
        "            # choose random index in features\n",
        "            index= random.choice(list(X.keys()))\n",
        "            batch_features[i] = X[index]\n",
        "            batch_labels[i] = Y[index]\n",
        "        yield batch_features, batch_labels\n",
        "'''\n",
        "\n",
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(train_c2d, train_c3d, train_sem,y_label):\n",
        "    X1, X2, X3, y = list(), list(), list(), list()\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for key, desc_list in train_c2d.items():\n",
        "            # retrieve the photo feature\n",
        "            c2d= train_c2d[key]\n",
        "            X1.append(c2d)\n",
        "            c3d= train_c3d[key]\n",
        "            X2.append(c3d)\n",
        "            sem=train_sem[key]\n",
        "            X3.append(sem)\n",
        "            y.append(y_label[key])\n",
        "            #print(len(photo))\n",
        "            yield [[array(X1), array(X2), array(X3)], array(y)]\n",
        "'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# data generator, intended to be used in a call to model.fit_generator()\\ndef data_generator(train_c2d, train_c3d, train_sem,y_label):\\n    X1, X2, X3, y = list(), list(), list(), list()\\n    # loop for ever over images\\n    while 1:\\n        for key, desc_list in train_c2d.items():\\n            # retrieve the photo feature\\n            c2d= train_c2d[key]\\n            X1.append(c2d)\\n            c3d= train_c3d[key]\\n            X2.append(c3d)\\n            sem=train_sem[key]\\n            X3.append(sem)\\n            y.append(y_label[key])\\n            #print(len(photo))\\n            yield [[array(X1), array(X2), array(X3)], array(y)]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "jyebhsztCelN"
      },
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "    # feature extractor model\n",
        "    inputs1 = Input(shape=(2048,))\n",
        "    #fe1 = Dropout(0.2)(inputs1)\n",
        "    fe1 = Dense(256, activation='relu')(inputs1)\n",
        "    #print(fe1)\n",
        "    outputs = Dense(21, activation='softmax')(fe1)\n",
        "    # tie it together [image, seq] [word]\n",
        "    model = Model(inputs=inputs1, outputs=outputs)\n",
        "        # compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # summarize model\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='/content/drive/MyDrive/finalattention/model/model_classify_domain.png', show_shapes=True)\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UaSjuhJD5OKc"
      }
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "6EbKHkR0CelP",
        "outputId": "a5e87392-7530-463b-c4b3-8040278c32fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "cell_type": "code",
      "source": [
        "model=baseline_model()\n",
        "epochs = 50\n",
        "batch_size=1260\n",
        "steps=len(train_vid_features)\n",
        "#print(i)\n",
        "\n",
        "    # create the data generator\n",
        "    #generator = data_generator(train_vid_features,Ytrain_label,batch_size)\n",
        "    # fit for one epoch\n",
        "    #model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    # model.evaluate_generator(generator=valid_generator)\n",
        "history = model.fit(Xtrain, Ytrain,validation_split=0.20, batch_size=batch_size, epochs=150)\n",
        "    # save model\n",
        "model.save('/content/drive/MyDrive/finalattention/model/model.h5')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m524,544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │           \u001b[38;5;34m5,397\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,397</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m529,941\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,941</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m529,941\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,941</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0308 - loss: 3.7433 - val_accuracy: 0.2222 - val_loss: 2.6701\n",
            "Epoch 2/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2768 - loss: 2.4540 - val_accuracy: 0.4206 - val_loss: 2.0165\n",
            "Epoch 3/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5149 - loss: 1.7119 - val_accuracy: 0.5873 - val_loss: 1.4338\n",
            "Epoch 4/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7222 - loss: 1.1445 - val_accuracy: 0.7540 - val_loss: 0.9982\n",
            "Epoch 5/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8333 - loss: 0.7789 - val_accuracy: 0.8294 - val_loss: 0.7178\n",
            "Epoch 6/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.8968 - loss: 0.5541 - val_accuracy: 0.8730 - val_loss: 0.5514\n",
            "Epoch 7/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9216 - loss: 0.4090 - val_accuracy: 0.8849 - val_loss: 0.4530\n",
            "Epoch 8/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9286 - loss: 0.3162 - val_accuracy: 0.8929 - val_loss: 0.3824\n",
            "Epoch 9/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9415 - loss: 0.2438 - val_accuracy: 0.9048 - val_loss: 0.3273\n",
            "Epoch 10/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9603 - loss: 0.1872 - val_accuracy: 0.8889 - val_loss: 0.2933\n",
            "Epoch 11/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9653 - loss: 0.1535 - val_accuracy: 0.9048 - val_loss: 0.2690\n",
            "Epoch 12/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9692 - loss: 0.1267 - val_accuracy: 0.9246 - val_loss: 0.2510\n",
            "Epoch 13/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9792 - loss: 0.1011 - val_accuracy: 0.9246 - val_loss: 0.2408\n",
            "Epoch 14/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9821 - loss: 0.0822 - val_accuracy: 0.9286 - val_loss: 0.2355\n",
            "Epoch 15/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.9851 - loss: 0.0696 - val_accuracy: 0.9325 - val_loss: 0.2291\n",
            "Epoch 16/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9871 - loss: 0.0581 - val_accuracy: 0.9365 - val_loss: 0.2210\n",
            "Epoch 17/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9921 - loss: 0.0482 - val_accuracy: 0.9444 - val_loss: 0.2141\n",
            "Epoch 18/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9940 - loss: 0.0414 - val_accuracy: 0.9484 - val_loss: 0.2081\n",
            "Epoch 19/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9970 - loss: 0.0358 - val_accuracy: 0.9484 - val_loss: 0.2020\n",
            "Epoch 20/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9980 - loss: 0.0301 - val_accuracy: 0.9444 - val_loss: 0.1965\n",
            "Epoch 21/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9980 - loss: 0.0252 - val_accuracy: 0.9484 - val_loss: 0.1925\n",
            "Epoch 22/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9990 - loss: 0.0217 - val_accuracy: 0.9484 - val_loss: 0.1900\n",
            "Epoch 23/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9990 - loss: 0.0194 - val_accuracy: 0.9484 - val_loss: 0.1883\n",
            "Epoch 24/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.9990 - loss: 0.0174 - val_accuracy: 0.9484 - val_loss: 0.1869\n",
            "Epoch 25/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9990 - loss: 0.0154 - val_accuracy: 0.9484 - val_loss: 0.1858\n",
            "Epoch 26/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9484 - val_loss: 0.1851\n",
            "Epoch 27/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9484 - val_loss: 0.1848\n",
            "Epoch 28/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9484 - val_loss: 0.1845\n",
            "Epoch 29/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9484 - val_loss: 0.1839\n",
            "Epoch 30/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9484 - val_loss: 0.1831\n",
            "Epoch 31/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9484 - val_loss: 0.1822\n",
            "Epoch 32/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9484 - val_loss: 0.1813\n",
            "Epoch 33/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9484 - val_loss: 0.1804\n",
            "Epoch 34/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9484 - val_loss: 0.1793\n",
            "Epoch 35/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9484 - val_loss: 0.1783\n",
            "Epoch 36/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9484 - val_loss: 0.1772\n",
            "Epoch 37/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9484 - val_loss: 0.1762\n",
            "Epoch 38/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9484 - val_loss: 0.1753\n",
            "Epoch 39/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9484 - val_loss: 0.1745\n",
            "Epoch 40/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9484 - val_loss: 0.1737\n",
            "Epoch 41/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9484 - val_loss: 0.1729\n",
            "Epoch 42/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9484 - val_loss: 0.1721\n",
            "Epoch 43/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9484 - val_loss: 0.1712\n",
            "Epoch 44/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9484 - val_loss: 0.1704\n",
            "Epoch 45/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9484 - val_loss: 0.1696\n",
            "Epoch 46/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9484 - val_loss: 0.1690\n",
            "Epoch 47/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9484 - val_loss: 0.1683\n",
            "Epoch 48/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9484 - val_loss: 0.1678\n",
            "Epoch 49/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9484 - val_loss: 0.1672\n",
            "Epoch 50/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9484 - val_loss: 0.1667\n",
            "Epoch 51/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9484 - val_loss: 0.1661\n",
            "Epoch 52/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9484 - val_loss: 0.1655\n",
            "Epoch 53/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9484 - val_loss: 0.1649\n",
            "Epoch 54/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9484 - val_loss: 0.1644\n",
            "Epoch 55/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9484 - val_loss: 0.1639\n",
            "Epoch 56/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9484 - val_loss: 0.1634\n",
            "Epoch 57/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9484 - val_loss: 0.1629\n",
            "Epoch 58/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9484 - val_loss: 0.1625\n",
            "Epoch 59/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9484 - val_loss: 0.1621\n",
            "Epoch 60/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9484 - val_loss: 0.1617\n",
            "Epoch 61/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9484 - val_loss: 0.1613\n",
            "Epoch 62/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9484 - val_loss: 0.1610\n",
            "Epoch 63/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9484 - val_loss: 0.1608\n",
            "Epoch 64/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9484 - val_loss: 0.1605\n",
            "Epoch 65/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9484 - val_loss: 0.1603\n",
            "Epoch 66/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9484 - val_loss: 0.1601\n",
            "Epoch 67/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9484 - val_loss: 0.1599\n",
            "Epoch 68/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9484 - val_loss: 0.1597\n",
            "Epoch 69/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9484 - val_loss: 0.1596\n",
            "Epoch 70/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9484 - val_loss: 0.1595\n",
            "Epoch 71/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9484 - val_loss: 0.1593\n",
            "Epoch 72/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9484 - val_loss: 0.1592\n",
            "Epoch 73/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9484 - val_loss: 0.1591\n",
            "Epoch 74/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9484 - val_loss: 0.1590\n",
            "Epoch 75/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9484 - val_loss: 0.1589\n",
            "Epoch 76/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9484 - val_loss: 0.1588\n",
            "Epoch 77/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9484 - val_loss: 0.1586\n",
            "Epoch 78/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9484 - val_loss: 0.1585\n",
            "Epoch 79/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9484 - val_loss: 0.1584\n",
            "Epoch 80/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9484 - val_loss: 0.1582\n",
            "Epoch 81/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9484 - val_loss: 0.1581\n",
            "Epoch 82/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9484 - val_loss: 0.1579\n",
            "Epoch 83/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9484 - val_loss: 0.1578\n",
            "Epoch 84/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9484 - val_loss: 0.1576\n",
            "Epoch 85/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1574\n",
            "Epoch 86/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1572\n",
            "Epoch 87/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1570\n",
            "Epoch 88/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1569\n",
            "Epoch 89/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1567\n",
            "Epoch 90/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.1565\n",
            "Epoch 91/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1563\n",
            "Epoch 92/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1561\n",
            "Epoch 93/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1560\n",
            "Epoch 94/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1558\n",
            "Epoch 95/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1557\n",
            "Epoch 96/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1555\n",
            "Epoch 97/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1554\n",
            "Epoch 98/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1553\n",
            "Epoch 99/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1551\n",
            "Epoch 100/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1550\n",
            "Epoch 101/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1549\n",
            "Epoch 102/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1547\n",
            "Epoch 103/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1546\n",
            "Epoch 104/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1545\n",
            "Epoch 105/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9484 - val_loss: 0.1544\n",
            "Epoch 106/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1543\n",
            "Epoch 107/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1542\n",
            "Epoch 108/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1541\n",
            "Epoch 109/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1540\n",
            "Epoch 110/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1539\n",
            "Epoch 111/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1538\n",
            "Epoch 112/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1537\n",
            "Epoch 113/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9484 - val_loss: 0.1536\n",
            "Epoch 114/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1535\n",
            "Epoch 115/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1535\n",
            "Epoch 116/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1534\n",
            "Epoch 117/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1533\n",
            "Epoch 118/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1532\n",
            "Epoch 119/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1531\n",
            "Epoch 120/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1531\n",
            "Epoch 121/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1530\n",
            "Epoch 122/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1529\n",
            "Epoch 123/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1528\n",
            "Epoch 124/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1527\n",
            "Epoch 125/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9484 - val_loss: 0.1527\n",
            "Epoch 126/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9484 - val_loss: 0.1526\n",
            "Epoch 127/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9484 - val_loss: 0.1525\n",
            "Epoch 128/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9484 - val_loss: 0.1525\n",
            "Epoch 129/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9484 - val_loss: 0.1524\n",
            "Epoch 130/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 9.9993e-04 - val_accuracy: 0.9484 - val_loss: 0.1523\n",
            "Epoch 131/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 9.9166e-04 - val_accuracy: 0.9484 - val_loss: 0.1523\n",
            "Epoch 132/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 9.8351e-04 - val_accuracy: 0.9484 - val_loss: 0.1522\n",
            "Epoch 133/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 9.7546e-04 - val_accuracy: 0.9484 - val_loss: 0.1521\n",
            "Epoch 134/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 9.6752e-04 - val_accuracy: 0.9484 - val_loss: 0.1521\n",
            "Epoch 135/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 9.5969e-04 - val_accuracy: 0.9484 - val_loss: 0.1520\n",
            "Epoch 136/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 9.5194e-04 - val_accuracy: 0.9484 - val_loss: 0.1519\n",
            "Epoch 137/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 9.4431e-04 - val_accuracy: 0.9484 - val_loss: 0.1519\n",
            "Epoch 138/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 9.3676e-04 - val_accuracy: 0.9484 - val_loss: 0.1518\n",
            "Epoch 139/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 9.2931e-04 - val_accuracy: 0.9484 - val_loss: 0.1517\n",
            "Epoch 140/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 9.2195e-04 - val_accuracy: 0.9484 - val_loss: 0.1517\n",
            "Epoch 141/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 9.1470e-04 - val_accuracy: 0.9524 - val_loss: 0.1516\n",
            "Epoch 142/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 9.0753e-04 - val_accuracy: 0.9524 - val_loss: 0.1516\n",
            "Epoch 143/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 9.0044e-04 - val_accuracy: 0.9524 - val_loss: 0.1515\n",
            "Epoch 144/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 8.9344e-04 - val_accuracy: 0.9524 - val_loss: 0.1514\n",
            "Epoch 145/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 8.8653e-04 - val_accuracy: 0.9524 - val_loss: 0.1514\n",
            "Epoch 146/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 8.7971e-04 - val_accuracy: 0.9524 - val_loss: 0.1513\n",
            "Epoch 147/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 8.7297e-04 - val_accuracy: 0.9524 - val_loss: 0.1513\n",
            "Epoch 148/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 8.6631e-04 - val_accuracy: 0.9524 - val_loss: 0.1512\n",
            "Epoch 149/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 8.5975e-04 - val_accuracy: 0.9524 - val_loss: 0.1511\n",
            "Epoch 150/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 8.5326e-04 - val_accuracy: 0.9524 - val_loss: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9LS25vj-ncMU",
        "outputId": "f0237d06-47ae-4dd2-d392-0b7c7cc4ac90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize training history\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('/content/drive/MyDrive/finalattention/model/accuracy.png')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('/content/drive/MyDrive/finalattention/model/loss.png')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'acc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a7eb5c1662de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "U-mi7nzICelR"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "2PW0EjgoCelS"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SseSS0N-CelU"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "model = load_model('/home/mh/mywork/classification/model_classify/model_4.h5')\n",
        "\n",
        "Ytest_label = load(open('/home/mh/mywork/dataset/MSVD/features/class_features/msvd_video_class_label_test.pkl', 'rb'))\n",
        "filename = '/home/mh/mywork/dataset/MSVD/new_testID.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "\n",
        "#load c2d features\n",
        "test_c2d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_resnet152_vlad_features_k_100.pkl', test)\n",
        "print('C2D: test=%d' % len(test_c2d_features))\n",
        "\n",
        "#load c3d features\n",
        "test_c3d_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/vlad/msvd_c3d_vlad_features_k_100.pkl', test)\n",
        "print('C3D: test=%d' % len(test_c3d_features))\n",
        "\n",
        "#load semantic features\n",
        "test_semantic_features = load_video_features('/home/mh/mywork/dataset/MSVD/features/msvd_sem_scn_300.pkl', test)\n",
        "print('Semantic: test=%d' % len(test_semantic_features))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7aCsQsLZCelW"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = load_model('drive/My Drive/Final Year Project/modelcom/model_01_077.h5')\n",
        "#features=load(open('features_resnet152_combined.pkl','rb'))\n",
        "#print(len(features))\n",
        "\n",
        "#accuracy for test\n",
        "predictions=list()\n",
        "pr_test=dict()\n",
        "y_label=list()\n",
        "count=0\n",
        "for i in test_vid_features:\n",
        "    #print(i)\n",
        "    x_n=np.array([test_vid_features[i]][0])\n",
        "    #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "    preds=model.predict([x_n])\n",
        "    labels = np.argmax(preds, axis=-1)\n",
        "    predictions.append(labels[0])\n",
        "    y_label.append(class_label[i])\n",
        "    pr_test[count]=i\n",
        "    count+=1\n",
        "\n",
        "predictions_test=np.array(predictions)\n",
        "ytest=np.array(y_label)\n",
        "pred_label = preprocessing.LabelBinarizer()\n",
        "test_predicted_label=pred_label.fit_transform(predictions_test)\n",
        "\n",
        "Ytest=Ytest.astype(int)\n",
        "\n",
        "#accuracy for train:\n",
        "predictions=list()\n",
        "pr_train=dict()\n",
        "y_label=list()\n",
        "count=0\n",
        "for i in train_vid_features:\n",
        "    #print(i)\n",
        "    x_n=np.array(train_vid_features[i])\n",
        "\n",
        "    #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "    preds=model.predict([x_n])\n",
        "    labels = np.argmax(preds, axis=-1)\n",
        "    predictions.append(labels[0])\n",
        "    y_label.append(class_label[i])\n",
        "    pr_train[count]=i\n",
        "    count+=1\n",
        "\n",
        "predictions_train=np.array(predictions)\n",
        "ytrain=np.array(y_label)\n",
        "pred_label = preprocessing.LabelBinarizer()\n",
        "train_predicted_label=pred_label.fit_transform(predictions_train)\n",
        "\n",
        "Ytrain=Ytrain.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hRacnjksCelZ"
      },
      "cell_type": "code",
      "source": [
        "print((predictions_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xUL7dLymCelb"
      },
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(Ytest.argmax(axis=1), test_predicted_label.argmax(axis=1))\n",
        "print(cm)\n",
        "\n",
        "print(\"Accuracy = \",accuracy_score(Ytest.argmax(axis=1), test_predicted_label.argmax(axis=1)))\n",
        "print(\"Accuracy = \",accuracy_score(Ytrain.argmax(axis=1), train_predicted_label.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuuHMps2Cele"
      },
      "cell_type": "code",
      "source": [
        "#to create domain feature vector\n",
        "model = load_model('modeluc1/model_49.h5')\n",
        "features=load(open('../features_uc_resnet152_updated.pkl','rb'))\n",
        "predictions=dict()\n",
        "for i in features:\n",
        "    #print(i)\n",
        "    x_n=np.array(features[i])\n",
        "    #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "    preds=model.predict([x_n])\n",
        "    predictions[i]=preds[0]\n",
        "\n",
        "print(predictions['10_077'])\n",
        "dump(predictions,open('domain_features.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BZsXNfcCelh"
      },
      "cell_type": "code",
      "source": [
        "fea=load(open('domain_features.pkl','rb'))\n",
        "print(fea)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kX3qPKC1Cell"
      },
      "cell_type": "code",
      "source": [
        "train_acc_x=np.zeros((15,1))\n",
        "train_acc_y=np.zeros((15,1))\n",
        "test_acc_x=np.zeros((15,1))\n",
        "test_acc_y=np.zeros((15,1))\n",
        "c=0\n",
        "for j in range(15,20,1):\n",
        "    print(j)\n",
        "    model = load_model('/home/mh/mywork/classification/model_classify_categoryloss/model_' + str(j) + '.h5')\n",
        "    predictions=list()\n",
        "    count=0\n",
        "    for i in train_vid_features:\n",
        "        #print(i)\n",
        "        x_n=np.array(train_vid_features[i])\n",
        "        #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "        preds=model.predict([x_n])\n",
        "        labels = np.argmax(preds, axis=-1)\n",
        "        predictions.append(labels[0])\n",
        "    predictions=np.array(predictions)\n",
        "    pred_label = preprocessing.LabelBinarizer()\n",
        "    predicted_label=pred_label.fit_transform(predictions)\n",
        "    Ytrain=Ytrain.astype(int)\n",
        "    train_acc_x[c]=c\n",
        "    train_acc_y[c]=accuracy_score(Ytrain.argmax(axis=1), predicted_label.argmax(axis=1))\n",
        "    predictions=list()\n",
        "    count=0\n",
        "    for i in test_vid_features:\n",
        "        #print(i)\n",
        "        x_n=np.array(test_vid_features[i])\n",
        "        #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "        preds=model.predict([x_n])\n",
        "        labels = np.argmax(preds, axis=-1)\n",
        "        predictions.append(labels[0])\n",
        "    predictions=np.array(predictions)\n",
        "    pred_label = preprocessing.LabelBinarizer()\n",
        "    predicted_label=pred_label.fit_transform(predictions)\n",
        "    Ytest=Ytest.astype(int)\n",
        "    test_acc_x[c]=c\n",
        "    test_acc_y[c]=accuracy_score(Ytest.argmax(axis=1), predicted_label.argmax(axis=1))\n",
        "    c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GWI9V7PCeln"
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.plot(train_acc_x, train_acc_y, 'g', label='Training accuracy')\n",
        "plt.plot(test_acc_x, test_acc_y, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCQXht-_Celq"
      },
      "cell_type": "code",
      "source": [
        "print(train_acc_y)\n",
        "print(test_acc_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkb7Fn9vCelt"
      },
      "cell_type": "code",
      "source": [
        "model = load_model('/home/mh/mywork/classification/model_classify_categoryloss/model_8.h5')\n",
        "features=load(open('/home/mh/mywork/dataset/MSVD/features/class_features/msvd_caption_features.pkl','rb'))\n",
        "#load training dataset (6K)\n",
        "filename = '/home/mh/mywork/dataset/MSVD/all_video_ID.txt'\n",
        "vid = load_set(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_O6k8mCCelv"
      },
      "cell_type": "code",
      "source": [
        "#accuracy for train:\n",
        "predictions=list()\n",
        "pr_vid=dict()\n",
        "y_label=list()\n",
        "count=0\n",
        "for i in features:\n",
        "    #print(i)\n",
        "    x_n=np.array(features[i])\n",
        "\n",
        "    #score = model.evaluate(x, y, batch_size=batch_size)\n",
        "    preds=model.predict([x_n])\n",
        "    labels = np.argmax(preds, axis=-1)\n",
        "    predictions.append(labels[0])\n",
        "    pr_vid[count]=i\n",
        "    count+=1\n",
        "\n",
        "predictions_train=np.array(predictions)\n",
        "pred_label = preprocessing.LabelBinarizer()\n",
        "predicted_label=pred_label.fit_transform(predictions)\n",
        "\n",
        "print(len(pr_vid))\n",
        "new_label=dict()\n",
        "for i in range(len(vid)):\n",
        "    new_label[pr_vid[i]]=predicted_label[i]\n",
        "\n",
        "dump(new_label,open('msvd_class_weights_category.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQJSVGsvCelx"
      },
      "cell_type": "code",
      "source": [
        "#get new class ids\n",
        "from numpy import argmax\n",
        "class_map={0:'actions',1:'animal',2:'cook',3:'music',4:'ride',5:'simpleactions'}\n",
        "#train\n",
        "train_domain=dict()\n",
        "for c in class_map:\n",
        "    train_domain[c]=list()\n",
        "for i in Ytrain_label:\n",
        "    class_label=argmax(Ytrain_label[i])\n",
        "    train_domain[class_label].append(i)\n",
        "\n",
        "#test\n",
        "test_domain=dict()\n",
        "for c in class_map:\n",
        "    test_domain[c]=list()\n",
        "for i in Ytest_label:\n",
        "    class_label=argmax(Ytest_label[i])\n",
        "    test_domain[class_label].append(i)\n",
        "\n",
        "\n",
        "dump(train_domain,open('cluster_domain_train_ids.pkl','wb'))\n",
        "dump(test_domain,open('cluster_domain_test_ids.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HR2ztbxWCely"
      },
      "cell_type": "code",
      "source": [
        "print(train_domain[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1mUpcvhrCel0"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}